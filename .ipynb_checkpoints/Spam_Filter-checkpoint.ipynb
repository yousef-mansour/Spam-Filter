{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_k62KJtCfagW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "root_download = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = root_download + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = root_download + \"20030228_spam.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "\n",
    "def fetch_spam_data(ham_url=HAM_URL, spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", ham_url), (\"spam.tar.bz2\", spam_url)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=spam_path)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Nctz31o4aBWe"
   },
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2oK16QCbanLU"
   },
   "outputs": [],
   "source": [
    "easy_ham_dir = os.path.join(SPAM_PATH, 'easy_ham')\n",
    "spam_dir = os.path.join(SPAM_PATH, 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FVYRsLNcYGGo"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lF4YncIldzwO"
   },
   "outputs": [],
   "source": [
    "#deleting the last element - 'cmds'.\n",
    "ham_names = np.array(sorted(os.listdir(easy_ham_dir)))[:-1]\n",
    "spam_names = np.array(sorted(os.listdir(spam_dir)))[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YfU5X3D-ePtK"
   },
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aC16Ebi8gX4I"
   },
   "outputs": [],
   "source": [
    "def get_email(category, filename):\n",
    "  directory = easy_ham_dir if category == 'ham' else spam_dir\n",
    "  with open(os.path.join(directory, filename), 'rb') as f:\n",
    "    return email.parser.BytesParser(policy = email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7tEUDQEthWdr"
   },
   "outputs": [],
   "source": [
    "hams = [get_email('ham', name) for name in ham_names]\n",
    "spams = [get_email('spam', name) for name in spam_names] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering the types of emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Q4v-hAO-nEbG"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_uOykMXuF5_",
    "outputId": "bee8f411-892a-4875-8fd0-a188f027d41c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('text/plain', 2408), ('multipart/signed', 68), ('multipart/alternative', 9), ('multipart/mixed', 10), ('multipart/related', 3), ('multipart/report', 2)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TYPES = [email.get_content_type() for email in (hams)]\n",
    "c = Counter(TYPES)\n",
    "c.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nuSQVUfvyC1",
    "outputId": "ae49801c-9c50-4b7f-971a-e31e4b9704ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('text/html', 183), ('text/plain', 218), ('multipart/mixed', 43), ('multipart/alternative', 47), ('multipart/related', 9)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TYPES = [email.get_content_type() for email in (spams)]\n",
    "c = Counter(TYPES)\n",
    "c.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OKube3j8Tvc",
    "outputId": "8a895f8f-8dad-4a5f-9780-1bb6d2f964f8"
   },
   "outputs": [],
   "source": [
    "X = np.array(hams + spams, dtype = 'object')\n",
    "y = np.array([1] * len(hams) + [0] * len(spams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1iARsGCO-UwB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zyPiR57--gMz"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scgnyWYK-13S"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "import urlextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_plain_text_test(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        a_tag.replace_with(\" HYPERLINK \")\n",
    "    return soup.get_text(separator = \" \", strip = True)\n",
    "\n",
    "def email_to_text_test(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text_test(html)\n",
    "    \n",
    "def refine_test(email_text):\n",
    "    url_extractor = urlextract.URLExtract()\n",
    "    urls = url_extractor.find_urls(email_text)\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "    email_text = re.sub(email_pattern, \"email_address\", email_text)\n",
    "    for url in urls:\n",
    "        email_text = re.sub(re.escape(url), 'url', email_text)\n",
    "    email_text = re.sub(r'\\d+', '', email_text)\n",
    "    email_text = re.sub(r'[^\\w\\s]', '', email_text)\n",
    "    return email_text\n",
    "\n",
    "def preprocess_test(email_parsed):\n",
    "    email_text = email_to_text_test(email_parsed)\n",
    "    email_text = refine_test(email_text)\n",
    "    cnt = Counter()\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    for word in email_text.split():\n",
    "        cnt[stemmer.stem(word.lower())] += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCounter(BaseEstimator, TransformerMixin, s):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        self.s = 0\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def html_to_plain_text(self, html):\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        for a_tag in soup.find_all('a'):\n",
    "            a_tag.replace_with(\" HYPERLINK \")\n",
    "        return soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "    def email_to_text(self, email):\n",
    "        html = None\n",
    "        for part in email.walk():\n",
    "            ctype = part.get_content_type()\n",
    "            if not ctype in (\"text/plain\", \"text/html\"):\n",
    "                continue\n",
    "            try:\n",
    "                content = part.get_content()\n",
    "            except:  # in case of encoding issues\n",
    "                content = str(part.get_payload())\n",
    "            if ctype == \"text/plain\":\n",
    "                return content\n",
    "            else:\n",
    "                html = content\n",
    "        if html:\n",
    "            return self.html_to_plain_text(html)\n",
    "\n",
    "    def refine(self, email_text):\n",
    "        url_extractor = urlextract.URLExtract()\n",
    "        urls = url_extractor.find_urls(email_text)#HERE\n",
    "        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "        email_text = re.sub(email_pattern, \"email_address\", email_text)\n",
    "        for url in urls:\n",
    "            email_text = re.sub(re.escape(url), 'url', email_text)\n",
    "        email_text = re.sub(r'\\d+', '', email_text)\n",
    "        email_text = re.sub(r'[^\\w\\s]', '', email_text)\n",
    "        return email_text\n",
    "\n",
    "    def preprocess(self, email_parsed):\n",
    "        email_text = self.email_to_text(email_parsed)\n",
    "        email_text = self.refine(email_text)\n",
    "        cnt = Counter()\n",
    "        stemmer = nltk.PorterStemmer()\n",
    "        for word in email_text.split():\n",
    "            cnt[stemmer.stem(word.lower())] += 1\n",
    "        return cnt\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            s += 1\n",
    "            X_transformed.append(self.preprocess(email))\n",
    "        return np.array(X_transformed)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pc \u001b[38;5;241m=\u001b[39m PCounter()\n\u001b[1;32m----> 2\u001b[0m X_preprocessed \u001b[38;5;241m=\u001b[39m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda_installed\\envs\\spam_filter_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[30], line 54\u001b[0m, in \u001b[0;36mPCounter.transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     52\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m email \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[1;32m---> 54\u001b[0m     X_transformed\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43memail\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(X_transformed)\n",
      "Cell \u001b[1;32mIn[30], line 44\u001b[0m, in \u001b[0;36mPCounter.preprocess\u001b[1;34m(self, email_parsed)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, email_parsed):\n\u001b[0;32m     43\u001b[0m     email_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memail_to_text(email_parsed)\n\u001b[1;32m---> 44\u001b[0m     email_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefine\u001b[49m\u001b[43m(\u001b[49m\u001b[43memail_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     cnt \u001b[38;5;241m=\u001b[39m Counter()\n\u001b[0;32m     46\u001b[0m     stemmer \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mPorterStemmer()\n",
      "Cell \u001b[1;32mIn[30], line 33\u001b[0m, in \u001b[0;36mPCounter.refine\u001b[1;34m(self, email_text)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrefine\u001b[39m(\u001b[38;5;28mself\u001b[39m, email_text):\n\u001b[0;32m     32\u001b[0m     url_extractor \u001b[38;5;241m=\u001b[39m urlextract\u001b[38;5;241m.\u001b[39mURLExtract()\n\u001b[1;32m---> 33\u001b[0m     urls \u001b[38;5;241m=\u001b[39m \u001b[43murl_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[43memail_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     email_pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[a-zA-Z0-9._\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m+-]+@[a-zA-Z0-9.-]+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.[a-zA-Z]\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m2,}\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     35\u001b[0m     email_text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(email_pattern, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memail_address\u001b[39m\u001b[38;5;124m\"\u001b[39m, email_text)\n",
      "File \u001b[1;32mE:\\Anaconda_installed\\envs\\spam_filter_env\\lib\\site-packages\\urlextract\\urlextract_core.py:936\u001b[0m, in \u001b[0;36mURLExtract.find_urls\u001b[1;34m(self, text, only_unique, check_dns, get_indices, with_schema_only)\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(urls)\n\u001b[0;32m    935\u001b[0m result_urls: List[Union[\u001b[38;5;28mstr\u001b[39m, Tuple[\u001b[38;5;28mstr\u001b[39m, Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]]]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 936\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43murls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    937\u001b[0m url_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m url:\n",
      "File \u001b[1;32mE:\\Anaconda_installed\\envs\\spam_filter_env\\lib\\site-packages\\urlextract\\urlextract_core.py:854\u001b[0m, in \u001b[0;36mURLExtract.gen_urls\u001b[1;34m(self, text, check_dns, get_indices, with_schema_only)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03mCreates generator over found URLs in given text.\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;124;03m:rtype: str|tuple(str, tuple(int, int))\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    853\u001b[0m tld_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 854\u001b[0m matched_tlds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tlds_re\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m matched_tlds:\n\u001b[0;32m    857\u001b[0m     tld \u001b[38;5;241m=\u001b[39m matched_tlds\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "pc = PCounter()\n",
    "X_preprocessed = pc.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(i, j , array):\n",
    "    l = i +  int((j - i)/2)\n",
    "    print('debug', i, l, j)\n",
    "    if(j - i < 2):\n",
    "        return i\n",
    "    \n",
    "    efh = False\n",
    "    esh = False\n",
    "    \n",
    "    try:\n",
    "        pc.transform(array[i: l])\n",
    "    except:\n",
    "        efh = True\n",
    "    try:\n",
    "        pc.transform(array[l+1: j])\n",
    "    except:\n",
    "        esh = True\n",
    "        \n",
    "    if(efh):\n",
    "        search(i, l,array)\n",
    "    else:\n",
    "        search(l+1, j, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug 0 1199 2399\n",
      "debug 0 599 1199\n",
      "debug 600 899 1199\n",
      "debug 600 749 899\n",
      "debug 750 824 899\n",
      "debug 750 787 824\n",
      "debug 788 806 824\n",
      "debug 788 797 806\n",
      "debug 798 802 806\n",
      "debug 803 804 806\n",
      "debug 805 805 806\n"
     ]
    }
   ],
   "source": [
    "error_index_instance = search(0, 2399, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PCounter()\n",
    "X_preprocessed = pc.transform(X_train[[805]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

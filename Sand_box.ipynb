{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b575602f",
   "metadata": {},
   "source": [
    "# Objective Transfomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0924205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import urlextract\n",
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "def html_to_plain_text(self, html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        a_tag.replace_with(\" HYPERLINK \")\n",
    "    return soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)\n",
    "    \n",
    "url_extractor = urlextract.URLExtract()\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893850e",
   "metadata": {},
   "source": [
    "# email preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dc689de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCounter(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, s = 0):\n",
    "        self.s = s\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def html_to_plain_text(self, html):\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        for a_tag in soup.find_all('a'):\n",
    "            a_tag.replace_with(\" HYPERLINK \")\n",
    "        return soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "    def email_to_text(self, email):\n",
    "        html = None\n",
    "        for part in email.walk():\n",
    "            ctype = part.get_content_type()\n",
    "            if not ctype in (\"text/plain\", \"text/html\", \"multipart/alternative\"):\n",
    "                continue\n",
    "            try:\n",
    "                content = part.get_content()\n",
    "            except:  # in case of encoding issues\n",
    "                content = str(part.get_payload())\n",
    "            if ctype == \"text/plain\":\n",
    "                return content\n",
    "            else:\n",
    "                html = content\n",
    "        if html:\n",
    "            return self.html_to_plain_text(html)\n",
    "        \n",
    "\n",
    "    def refine(self, email_text):\n",
    "        url_extractor = urlextract.URLExtract()\n",
    "        urls = url_extractor.find_urls(email_text)#HERE\n",
    "        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "        email_text = re.sub(email_pattern, \"email_address\", email_text)\n",
    "        for url in urls:\n",
    "            email_text = re.sub(re.escape(url), 'url', email_text)\n",
    "        email_text = re.sub(r'\\d+', '', email_text)\n",
    "        email_text = re.sub(r'[^\\w\\s]', '', email_text)\n",
    "        return email_text\n",
    "\n",
    "    def preprocess(self, email_parsed):\n",
    "        email_text = self.email_to_text(email_parsed)\n",
    "        email_text = self.refine(email_text)\n",
    "        cnt = Counter()\n",
    "        stemmer = nltk.PorterStemmer()\n",
    "        for word in email_text.split():\n",
    "            cnt[stemmer.stem(word.lower())] += 1\n",
    "        return cnt\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            self.s += 1\n",
    "            X_transformed.append(self.preprocess(email))\n",
    "        return np.array(X_transformed)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d18e0fb",
   "metadata": {},
   "source": [
    "# Importing an email as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65cdc910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27dfe458",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_path = os.path.join('datasets', 'spam', 'easy_ham', '00001.7c53336b37003a9286aba55d2945844c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c65ccc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(email_path) as email_file:\n",
    "    email_opened = email_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6ffb68",
   "metadata": {},
   "source": [
    "# Importing an email using email parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "736d6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "200443c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(email_path, 'rb') as email_file:\n",
    "    email_parsed = email.parser.BytesParser(policy = email.policy.default).parse(email_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58aea96",
   "metadata": {},
   "source": [
    "# Convert from email to word counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef565cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PCounter()\n",
    "cnt = pc.transform([email_parsed])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e1bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
